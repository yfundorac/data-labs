<!DOCTYPE html>

<html class="client-nojs" dir="ltr" lang="en">
<head>
<meta charset="utf-8"/>
<title>Semi-supervised learning - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Semi-supervised_learning","wgTitle":"Semi-supervised learning","wgCurRevisionId":913183638,"wgRevisionId":913183638,"wgArticleId":2829632,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 errors: missing periodical","CS1 maint: multiple names: authors list","All accuracy disputes","Articles with disputed statements from November 2017","Machine learning"],"wgBreakFrames":!1,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],
"wgRelevantPageName":"Semi-supervised_learning","wgRelevantArticleId":2829632,"wgRequestId":"XaN1zApAMFYAAGGQxxoAAABC","wgCSPNonce":!1,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q1041418","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading",
"ext.math.styles":"ready","ext.cite.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"};RLPAGEMODULES=["ext.math.scripts","ext.cite.ux-enhancements","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming",
"ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link href="/w/load.php?lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta content="" name="ResourceLoaderDynamicStyles"/>
<link href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector" rel="stylesheet"/>
<meta content="MediaWiki 1.35.0-wmf.1" name="generator"/>
<meta content="origin" name="referrer"/>
<meta content="origin-when-crossorigin" name="referrer"/>
<meta content="origin-when-cross-origin" name="referrer"/>
<meta content="https://upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png" property="og:image"/>
<link href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Semi-supervised_learning" rel="alternate"/>
<link href="/w/index.php?title=Semi-supervised_learning&amp;action=edit" rel="alternate" title="Edit this page" type="application/x-wiki"/>
<link href="/w/index.php?title=Semi-supervised_learning&amp;action=edit" rel="edit" title="Edit this page"/>
<link href="/static/apple-touch/wikipedia.png" rel="apple-touch-icon"/>
<link href="/static/favicon/wikipedia.ico" rel="shortcut icon"/>
<link href="/w/opensearch_desc.php" rel="search" title="Wikipedia (en)" type="application/opensearchdescription+xml"/>
<link href="//en.wikipedia.org/w/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>
<link href="//creativecommons.org/licenses/by-sa/3.0/" rel="license"/>
<link href="https://en.wikipedia.org/wiki/Semi-supervised_learning" rel="canonical"/>
<link href="//login.wikimedia.org" rel="dns-prefetch"/>
<link href="//meta.wikimedia.org" rel="dns-prefetch"/>
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Semi-supervised_learning rootpage-Semi-supervised_learning skin-vector action-view">
<div class="noprint" id="mw-page-base"></div>
<div class="noprint" id="mw-head-base"></div>
<div class="mw-body" id="content" role="main">
<a id="top"></a>
<div class="mw-body-content" id="siteNotice"><!-- CentralNotice --></div>
<div class="mw-indicators mw-body-content">
</div>
<h1 class="firstHeading" id="firstHeading" lang="en">Semi-supervised learning</h1>
<div class="mw-body-content" id="bodyContent">
<div class="noprint" id="siteSub">From Wikipedia, the free encyclopedia</div>
<div id="contentSub"></div>
<div id="jump-to-nav"></div>
<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
<a class="mw-jump-link" href="#p-search">Jump to search</a>
<div class="mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br/><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a class="image" href="/wiki/File:Kernel_Machine.svg"><img alt="Kernel Machine.svg" data-file-height="233" data-file-width="512" decoding="async" height="100" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" width="220"/></a></td></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a class="mw-selflink selflink">Semi-supervised learning</a></li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br/><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b> • <b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>
<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a class="mw-redirect" href="/wiki/CURE_data_clustering_algorithm" title="CURE data clustering algorithm">CURE</a></li>
<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">Expectation–maximization (EM)</a></li>
<li><br/><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a class="mw-redirect" href="/wiki/Mean-shift" title="Mean-shift">Mean-shift</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a class="mw-redirect" href="/wiki/Canonical_correlation_analysis" title="Canonical correlation analysis">CCA</a></li>
<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/K-nearest_neighbors_classification" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>
<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a class="mw-redirect" href="/wiki/Artificial_neural_networks" title="Artificial neural networks">Artificial neural networks</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>
<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>
<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>
<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>
<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>
<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a class="mw-redirect" href="/wiki/Bias%E2%80%93variance_dilemma" title="Bias–variance dilemma">Bias–variance dilemma</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NIPS</a></li>
<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>
<li><a class="external text" href="https://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>
<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>
</div></div></div></td>
</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<div class="thumb tright"><div class="thumbinner" style="width:196px;"><a class="image" href="/wiki/File:Example_of_unlabeled_data_in_semisupervised_learning.png"><img alt="" class="thumbimage" data-file-height="449" data-file-width="388" decoding="async" height="225" src="//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png/194px-Example_of_unlabeled_data_in_semisupervised_learning.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png/291px-Example_of_unlabeled_data_in_semisupervised_learning.png 1.5x, //upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png 2x" width="194"/></a> <div class="thumbcaption"><div class="magnify"><a class="internal" href="/wiki/File:Example_of_unlabeled_data_in_semisupervised_learning.png" title="Enlarge"></a></div>An example of the influence of unlabeled data in semi-supervised learning.  The top panel shows a decision boundary we might adopt after seeing only one positive (white circle) and one negative (black circle) example.  The bottom panel shows a decision boundary we might adopt if, in addition to the two labeled examples, we were given a collection of unlabeled data (gray circles).  This could be viewed as performing <a href="/wiki/Cluster_analysis" title="Cluster analysis">clustering</a> and then labeling the clusters with the labeled data, pushing the decision boundary away from high-density regions, or learning an underlying one-dimensional manifold where the data reside.</div></div></div>
<p><b>Semi-supervised learning</b> is a class of <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> tasks and techniques that also make use of unlabeled <a href="/wiki/Data" title="Data">data</a> for training – typically a small amount of <a href="/wiki/Labeled_data" title="Labeled data">labeled data</a> with a large amount of unlabeled data.  Semi-supervised learning falls between <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised learning</a> (without any labeled training data) and <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a> (with completely labeled training data).  Many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy. The acquisition of labeled data for a learning problem often requires a skilled human agent (e.g. to transcribe an audio segment) or a physical experiment (e.g. determining the 3D structure of a protein or determining whether there is oil at a particular location). The cost associated with the labeling process thus may render a fully labeled training set infeasible, whereas acquisition of unlabeled data is relatively inexpensive. In such situations, semi-supervised learning can be of great practical value.  Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning.
</p><p>As in the supervised learning framework, we are given a set of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle l}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>l</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle l}</annotation>
</semantics>
</math></span><img alt="l" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/829091f745070b9eb97a80244129025440a1cfac" style="vertical-align: -0.338ex; width:0.693ex; height:2.176ex;"/></span> <a class="mw-redirect" href="/wiki/Independent_identically_distributed" title="Independent identically distributed">independently identically distributed</a> examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{1},\dots ,x_{l}\in X}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
</mrow>
</msub>
<mo>∈<!-- ∈ --></mo>
<mi>X</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{1},\dots ,x_{l}\in X}</annotation>
</semantics>
</math></span><img alt="x_{1},\dots ,x_{l}\in X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76da26bfd12e40809f4b2dae37ecca34ad1c825c" style="vertical-align: -0.671ex; width:14.435ex; height:2.509ex;"/></span> with corresponding labels <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle y_{1},\dots ,y_{l}\in Y}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
</mrow>
</msub>
<mo>∈<!-- ∈ --></mo>
<mi>Y</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle y_{1},\dots ,y_{l}\in Y}</annotation>
</semantics>
</math></span><img alt="y_{1},\dots ,y_{l}\in Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b376abba952ea1dca784912adb9a3bfd006eb6b" style="vertical-align: -0.671ex; width:13.847ex; height:2.509ex;"/></span>.  Additionally, we are given <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle u}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>u</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle u}</annotation>
</semantics>
</math></span><img alt="u" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3e6bb763d22c20916ed4f0bb6bd49d7470cffd8" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span> unlabeled examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{l+1},\dots ,x_{l+u}\in X}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</msub>
<mo>∈<!-- ∈ --></mo>
<mi>X</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{l+1},\dots ,x_{l+u}\in X}</annotation>
</semantics>
</math></span><img alt="x_{l+1},\dots ,x_{l+u}\in X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/60a05a61c90d36f1a9def946c7dd83e826162b26" style="vertical-align: -0.671ex; width:18.423ex; height:2.509ex;"/></span>.  Semi-supervised learning attempts to make use of this combined information to surpass the <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a> performance that could be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.
</p><p>Semi-supervised learning may refer to either <a href="/wiki/Transduction_(machine_learning)" title="Transduction (machine learning)">transductive learning</a> or <a href="/wiki/Inductive_reasoning" title="Inductive reasoning">inductive learning</a><sup class="reference" id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup>  The goal of transductive learning is to infer the correct labels for the given unlabeled data <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{l+1},\dots ,x_{l+u}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{l+1},\dots ,x_{l+u}}</annotation>
</semantics>
</math></span><img alt="x_{l+1},\dots ,x_{l+u}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76df04fc221300e6e1d6de65cf9d4f8614280ae6" style="vertical-align: -0.671ex; width:13.602ex; height:2.009ex;"/></span> only.  The goal of inductive learning is to infer the correct mapping from <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle X}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>X</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle X}</annotation>
</semantics>
</math></span><img alt="X" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;"/></span> to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Y}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>Y</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
</semantics>
</math></span><img alt="Y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;"/></span>.
</p><p>Intuitively, we can think of the learning problem as an exam and labeled data as the few example problems that the teacher solved in class.  The teacher also provides a set of unsolved problems.  In the transductive setting, these unsolved problems are a take-home exam and you want to do well on them in particular.  In the inductive setting, these are practice problems of the sort you will encounter on the in-class exam.
</p><p>It is unnecessary (and, according to <a class="mw-redirect" href="/wiki/Vapnik%27s_principle" title="Vapnik's principle">Vapnik's principle</a>, imprudent) to perform transductive learning by way of inferring a classification rule over the entire input space; however, in practice, algorithms formally designed for transduction or induction are often used interchangeably.
</p>
<div class="toc" id="toc"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Assumptions_used"><span class="tocnumber">1</span> <span class="toctext">Assumptions used</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Continuity_assumption"><span class="tocnumber">1.1</span> <span class="toctext">Continuity assumption</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Cluster_assumption"><span class="tocnumber">1.2</span> <span class="toctext">Cluster assumption</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Manifold_assumption"><span class="tocnumber">1.3</span> <span class="toctext">Manifold assumption</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-5"><a href="#History"><span class="tocnumber">2</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Methods"><span class="tocnumber">3</span> <span class="toctext">Methods</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#Generative_models"><span class="tocnumber">3.1</span> <span class="toctext">Generative models</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Low-density_separation"><span class="tocnumber">3.2</span> <span class="toctext">Low-density separation</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Graph-based_methods"><span class="tocnumber">3.3</span> <span class="toctext">Graph-based methods</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Heuristic_approaches"><span class="tocnumber">3.4</span> <span class="toctext">Heuristic approaches</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="#In_human_cognition"><span class="tocnumber">4</span> <span class="toctext">In human cognition</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="#External_links"><span class="tocnumber">7</span> <span class="toctext">External links</span></a></li>
</ul>
</div>
<h2><span class="mw-headline" id="Assumptions_used">Assumptions used</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=1" title="Edit section: Assumptions used">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In order to make any use of unlabeled data, we must assume some structure to the underlying distribution of data.  Semi-supervised learning algorithms make use of at least one of the following assumptions.
<sup class="reference" id="cite_ref-Chapelle_2-0"><a href="#cite_note-Chapelle-2">[2]</a></sup>
</p>
<h3><span class="mw-headline" id="Continuity_assumption">Continuity assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=2" title="Edit section: Continuity assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><i>Points which are close to each other are more likely to share a label.</i> This is also generally assumed in supervised learning and yields a preference for geometrically simple <a href="/wiki/Decision_boundary" title="Decision boundary">decision boundaries</a>.  In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so that there are fewer points close to each other but in different classes.
</p>
<h3><span class="mw-headline" id="Cluster_assumption">Cluster assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=3" title="Edit section: Cluster assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><i>The data tend to form discrete clusters, and points in the same cluster are more likely to share a label</i> (although data sharing a label may be spread across multiple clusters).  This is a special case of the smoothness assumption and gives rise to <a href="/wiki/Feature_learning" title="Feature learning">feature learning</a> with clustering algorithms.
</p>
<h3><span class="mw-headline" id="Manifold_assumption">Manifold assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=4" title="Edit section: Manifold assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><i>The data lie approximately on a <a href="/wiki/Manifold" title="Manifold">manifold</a> of much lower dimension than the input space.</i>  In this case we can attempt to learn the manifold using both the labeled and unlabeled data to avoid the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>.  Then learning can proceed using distances and densities defined on the manifold.
</p><p>The manifold assumption is practical when high-dimensional data are being generated by some process that may be hard to model directly, but which only has a few degrees of freedom.  For instance, human voice is controlled by a few vocal folds,<sup class="reference" id="cite_ref-StevensKN_3-0"><a href="#cite_note-StevensKN-3">[3]</a></sup> and images of various facial expressions are controlled by a few muscles.  We would like in these cases to use distances and smoothness in the natural space of the generating problem, rather than in the space of all possible acoustic waves or images respectively.
</p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=5" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The heuristic approach of <i>self-training</i> (also known as <i>self-learning</i> or <i>self-labeling</i>) is historically the oldest approach to semi-supervised learning,<sup class="reference" id="cite_ref-Chapelle_2-1"><a href="#cite_note-Chapelle-2">[2]</a></sup> with examples of applications starting in the 1960s (see for instance Scudder (1965)<sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup>).
</p><p>The transductive learning framework was formally introduced by <a href="/wiki/Vladimir_Vapnik" title="Vladimir Vapnik">Vladimir Vapnik</a> in the 1970s.<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> Interest in inductive learning using generative models also began in the 1970s.  A <a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning"><i>probably approximately correct</i> learning</a> bound for semi-supervised learning of a Gaussian mixture was demonstrated by Ratsaby and Venkatesh in 1995.<sup class="reference" id="cite_ref-Ratsaby_6-0"><a href="#cite_note-Ratsaby-6">[6]</a></sup>
</p><p>Semi-supervised learning has recently become more popular and practically relevant due to the variety of problems for which vast quantities of unlabeled data are available—e.g. text on websites, protein sequences, or images.  For a review of recent work see a survey article by Zhu (2008).<sup class="reference" id="cite_ref-survey_7-0"><a href="#cite_note-survey-7">[7]</a></sup>
</p>
<h2><span class="mw-headline" id="Methods">Methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=6" title="Edit section: Methods">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Generative_models">Generative models</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=7" title="Edit section: Generative models">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Generative approaches to statistical learning first seek to estimate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(x|y)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(x|y)}</annotation>
</semantics>
</math></span><img alt="p(x|y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b99b32ed9c0b94759956558b359f8da3ab98a23f" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.2ex; height:2.843ex;"/></span>,<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a class="mw-redirect" href="/wiki/Wikipedia:Disputed_statement" title="Wikipedia:Disputed statement"><span title="This claim has reliable sources with contradicting facts (November 2017)">disputed</span></a> <span class="metadata"> – <a href="/wiki/Talk:Semi-supervised_learning" title="Talk:Semi-supervised learning">discuss</a></span></i>]</sup> the distribution of data points belonging to each class.  The probability <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(y|x)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(y|x)}</annotation>
</semantics>
</math></span><img alt="p(y|x)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3cad17372ea694e639c3881b2b5583632cdaa0ac" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.2ex; height:2.843ex;"/></span> that a given point <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>x</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x}</annotation>
</semantics>
</math></span><img alt="x" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;"/></span> has label <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle y}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>y</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle y}</annotation>
</semantics>
</math></span><img alt="y" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;"/></span> is then proportional to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(x|y)p(y)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>y</mi>
<mo stretchy="false">)</mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(x|y)p(y)}</annotation>
</semantics>
</math></span><img alt="p(x|y)p(y)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c143e52e1ea6009cb114283e625d14e3d6c8374" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.334ex; height:2.843ex;"/></span> by <a href="/wiki/Bayes%27_theorem" title="Bayes' theorem">Bayes' rule</a>.  Semi-supervised learning with generative models can be viewed either as an extension of supervised learning (classification plus information about <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(x)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(x)}</annotation>
</semantics>
</math></span><img alt="p(x)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8cb7afced134ef75572e5314a5d278c2d644f438" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:4.398ex; height:2.843ex;"/></span>) or as an extension of unsupervised learning (clustering plus some labels).
</p><p>Generative models assume that the distributions take some particular form <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(x|y,\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>y</mi>
<mo>,</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(x|y,\theta )}</annotation>
</semantics>
</math></span><img alt="p(x|y,\theta )" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/814281f66d6aa10e386cfd04488bfe0afd8f13de" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:8.325ex; height:2.843ex;"/></span> parameterized by the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \theta }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>θ<!-- θ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \theta }</annotation>
</semantics>
</math></span><img alt="\theta " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/></span>.  If these assumptions are incorrect, the unlabeled data may actually decrease the accuracy of the solution relative to what would have been obtained from labeled data alone.
<sup class="reference" id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>  
However, if the assumptions are correct, then the unlabeled data necessarily improves performance.<sup class="reference" id="cite_ref-Ratsaby_6-1"><a href="#cite_note-Ratsaby-6">[6]</a></sup>
</p><p>The unlabeled data are distributed according to a mixture of individual-class distributions.  In order to learn the mixture distribution from the unlabeled data, it must be identifiable, that is, different parameters must yield different summed distributions.  Gaussian mixture distributions are identifiable and commonly used for generative models.
</p><p>The parameterized <a class="mw-redirect" href="/wiki/Joint_distribution" title="Joint distribution">joint distribution</a> can be written as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p(x,y|\theta )=p(y|\theta )p(x|y,\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>y</mi>
<mo>,</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p(x,y|\theta )=p(y|\theta )p(x|y,\theta )}</annotation>
</semantics>
</math></span><img alt="p(x,y|\theta )=p(y|\theta )p(x|y,\theta )" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e2ac1816799d6f03d29974d31d46052577af1d76" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:25.53ex; height:2.843ex;"/></span> by using the <a href="/wiki/Chain_rule_(probability)" title="Chain rule (probability)">Chain rule</a>.  Each parameter vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \theta }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>θ<!-- θ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \theta }</annotation>
</semantics>
</math></span><img alt="\theta " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;"/></span> is associated with a decision function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f_{\theta }(x)={\underset {y}{\operatorname {argmax} }}\ p(y|x,\theta )}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>f</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>θ<!-- θ --></mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mi>argmax</mi>
<mi>y</mi>
</munder>
</mrow>
<mtext> </mtext>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>x</mi>
<mo>,</mo>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f_{\theta }(x)={\underset {y}{\operatorname {argmax} }}\ p(y|x,\theta )}</annotation>
</semantics>
</math></span><img alt="f_{\theta }(x)={\underset {y}{\operatorname {argmax} }}\ p(y|x,\theta )" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f945455e371eed97409081ee3b088dee3aa03e49" style="vertical-align: -2.671ex; width:24.758ex; height:4.676ex;"/></span>.  
The parameter is then chosen based on fit to both the labeled and unlabeled data, weighted by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>λ<!-- λ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda }</annotation>
</semantics>
</math></span><img alt="\lambda " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;"/></span>:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\underset {\Theta }{\operatorname {argmax} }}\left(\log p(\{x_{i},y_{i}\}_{i=1}^{l}|\theta )+\lambda \log p(\{x_{i}\}_{i=l+1}^{l+u}|\theta )\right)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mi>argmax</mi>
<mi mathvariant="normal">Θ<!-- Θ --></mi>
</munder>
</mrow>
<mrow>
<mo>(</mo>
<mrow>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mo fence="false" stretchy="false">{</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<msubsup>
<mo fence="false" stretchy="false">}</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
</mrow>
</msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>λ<!-- λ --></mi>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mo fence="false" stretchy="false">{</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<msubsup>
<mo fence="false" stretchy="false">}</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mi>l</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>θ<!-- θ --></mi>
<mo stretchy="false">)</mo>
</mrow>
<mo>)</mo>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\underset {\Theta }{\operatorname {argmax} }}\left(\log p(\{x_{i},y_{i}\}_{i=1}^{l}|\theta )+\lambda \log p(\{x_{i}\}_{i=l+1}^{l+u}|\theta )\right)}</annotation>
</semantics>
</math></span><img alt="{\underset {\Theta }{\operatorname {argmax} }}\left(\log p(\{x_{i},y_{i}\}_{i=1}^{l}|\theta )+\lambda \log p(\{x_{i}\}_{i=l+1}^{l+u}|\theta )\right)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a7aa70fbdeafcdc211033ec8e176fa857a802f6" style="vertical-align: -2.505ex; width:50.262ex; height:4.843ex;"/></span></dd></dl>
<p><sup class="reference" id="cite_ref-SSL_EoML_9-0"><a href="#cite_note-SSL_EoML-9">[9]</a></sup>
</p>
<h3><span class="mw-headline" id="Low-density_separation">Low-density separation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=8" title="Edit section: Low-density separation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Another major class of method attempts to place boundaries in regions where there are few data points (labeled or unlabeled).  One of the most commonly used algorithms is the <a class="mw-redirect" href="/wiki/Support_vector_machine#Transductive_support_vector_machines" title="Support vector machine">transductive support vector machine</a>, or TSVM (which, despite its name, may be used for inductive learning as well).  Whereas <a class="mw-redirect" href="/wiki/Support_vector_machines" title="Support vector machines">support vector machines</a> for supervised learning seek a decision boundary with maximal <a href="/wiki/Margin_(machine_learning)" title="Margin (machine learning)">margin</a> over the labeled data, the goal of TSVM is a labeling of the unlabeled data such that the decision boundary has maximal margin over all of the data.  In addition to the standard <a href="/wiki/Hinge_loss" title="Hinge loss">hinge loss</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (1-yf(x))_{+}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>−<!-- − --></mo>
<mi>y</mi>
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<msub>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo>+</mo>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (1-yf(x))_{+}}</annotation>
</semantics>
</math></span><img alt="(1-yf(x))_{+}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/56caba62f006f7d77e475adb6ea090fd8dc829da" style="vertical-align: -0.838ex; width:12.896ex; height:2.843ex;"/></span> for labeled data, a loss function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (1-|f(x)|)_{+}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo>+</mo>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (1-|f(x)|)_{+}}</annotation>
</semantics>
</math></span><img alt="(1-|f(x)|)_{+}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3c64faf68d1ad0a3c9f9ea7fcf0521491e86453d" style="vertical-align: -0.838ex; width:13.034ex; height:2.843ex;"/></span> is introduced over the unlabeled data by letting <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle y=\operatorname {sign} {f(x)}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>y</mi>
<mo>=</mo>
<mi>sign</mi>
<mo>⁡<!-- ⁡ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle y=\operatorname {sign} {f(x)}}</annotation>
</semantics>
</math></span><img alt="y=\operatorname {sign} {f(x)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1b9c83b2319d29f77f9c6ffc8b4a8fd3b426bb36" style="vertical-align: -0.838ex; width:13.077ex; height:2.843ex;"/></span>.  TSVM then selects <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f^{*}(x)=h^{*}(x)+b}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mi>f</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo>∗<!-- ∗ --></mo>
</mrow>
</msup>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<msup>
<mi>h</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo>∗<!-- ∗ --></mo>
</mrow>
</msup>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>b</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f^{*}(x)=h^{*}(x)+b}</annotation>
</semantics>
</math></span><img alt="f^{*}(x)=h^{*}(x)+b" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/188cec367978923197f8da14e236e6ec925b7fc1" style="vertical-align: -0.838ex; width:17.982ex; height:2.843ex;"/></span> from a <a href="/wiki/Reproducing_kernel_Hilbert_space" title="Reproducing kernel Hilbert space">reproducing kernel Hilbert space</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>
</mrow>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\mathcal {H}}}</annotation>
</semantics>
</math></span><img alt="{\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span> by minimizing the <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularized</a> <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk</a>:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle f^{*}={\underset {f}{\operatorname {argmin} }}\left(\displaystyle \sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\lambda _{1}\|h\|_{\mathcal {H}}^{2}+\lambda _{2}\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\right)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mi>f</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo>∗<!-- ∗ --></mo>
</mrow>
</msup>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mi>argmin</mi>
<mi>f</mi>
</munder>
</mrow>
<mrow>
<mo>(</mo>
<mstyle displaystyle="true" scriptlevel="0">
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
</mrow>
</munderover>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>−<!-- − --></mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<msub>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo>+</mo>
</mrow>
</msub>
<mo>+</mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<mi>h</mi>
<msubsup>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msubsup>
<mo>+</mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mi>l</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</munderover>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo>+</mo>
</mrow>
</msub>
</mstyle>
<mo>)</mo>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle f^{*}={\underset {f}{\operatorname {argmin} }}\left(\displaystyle \sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\lambda _{1}\|h\|_{\mathcal {H}}^{2}+\lambda _{2}\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\right)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle f^{*}={\underset {f}{\operatorname {argmin} }}\left(\displaystyle \sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\lambda _{1}\|h\|_{\mathcal {H}}^{2}+\lambda _{2}\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\right)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/280fd60cca5b00621dffd739326086e6d1152944" style="vertical-align: -3.171ex; width:68.93ex; height:7.509ex;"/></span></dd></dl>
<p>An exact solution is intractable due to the non-<a href="/wiki/Convex_function" title="Convex function">convex</a> term <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (1-|f(x)|)_{+}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo>+</mo>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (1-|f(x)|)_{+}}</annotation>
</semantics>
</math></span><img alt="(1-|f(x)|)_{+}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3c64faf68d1ad0a3c9f9ea7fcf0521491e86453d" style="vertical-align: -0.838ex; width:13.034ex; height:2.843ex;"/></span>, so research has focused on finding useful approximations.<sup class="reference" id="cite_ref-SSL_EoML_9-1"><a href="#cite_note-SSL_EoML-9">[9]</a></sup>
</p><p>Other approaches that implement low-density separation include Gaussian process models, information regularization, and entropy minimization (of which TSVM is a special case).
</p>
<h3><span class="mw-headline" id="Graph-based_methods">Graph-based methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=9" title="Edit section: Graph-based methods">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Graph-based methods for semi-supervised learning use a graph representation of the data, with a node for each labeled and unlabeled example.  The graph may be constructed using domain knowledge or similarity of examples; two common methods are to connect each data point to its <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle k}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>k</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle k}</annotation>
</semantics>
</math></span><img alt="k" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" style="vertical-align: -0.338ex; width:1.211ex; height:2.176ex;"/></span> nearest neighbors or to examples within some distance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \epsilon }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>ϵ<!-- ϵ --></mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \epsilon }</annotation>
</semantics>
</math></span><img alt="\epsilon " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3837cad72483d97bcdde49c85d3b7b859fb3fd2" style="vertical-align: -0.338ex; width:0.944ex; height:1.676ex;"/></span>.  The weight <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle W_{ij}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>W</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle W_{ij}}</annotation>
</semantics>
</math></span><img alt="W_{ij}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29c09e9d719bb634d8ca5a6172b0562b945bf325" style="vertical-align: -1.005ex; width:3.671ex; height:2.843ex;"/></span> of an edge between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
</semantics>
</math></span><img alt="x_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{j}}</annotation>
</semantics>
</math></span><img alt="x_{j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db47cb3d2f9496205a17a6856c91c1d3d363ccd" style="vertical-align: -1.005ex; width:2.239ex; height:2.343ex;"/></span> is then set to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle e^{\frac {-\|x_{i}-x_{j}\|^{2}}{\epsilon }}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mi>e</mi>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<mo>−<!-- − --></mo>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<msup>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
</mrow>
<mi>ϵ<!-- ϵ --></mi>
</mfrac>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle e^{\frac {-\|x_{i}-x_{j}\|^{2}}{\epsilon }}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle e^{\frac {-\|x_{i}-x_{j}\|^{2}}{\epsilon }}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f664e52a49df1855b25aff5a35b7a6a5d0d52764" style="vertical-align: -0.338ex; width:9.167ex; height:4.509ex;"/></span>.
</p><p>Within the framework of <a href="/wiki/Manifold_regularization" title="Manifold regularization">manifold regularization</a>,<sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup>
<sup class="reference" id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup>
the graph serves as a proxy for the manifold.  A term is added to the standard <a href="/wiki/Tikhonov_regularization" title="Tikhonov regularization">Tikhonov regularization</a> problem to enforce smoothness of the solution relative to the manifold (in the intrinsic space of the problem) as well as relative to the ambient input space.  The minimization problem becomes
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\underset {f\in {\mathcal {H}}}{\operatorname {argmin} }}\left({\frac {1}{l}}\displaystyle \sum _{i=1}^{l}V(f(x_{i}),y_{i})+\lambda _{A}\|f\|_{\mathcal {H}}^{2}+\lambda _{I}\int _{\mathcal {M}}\|\nabla _{\mathcal {M}}f(x)\|^{2}dp(x)\right)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<munder>
<mi>argmin</mi>
<mrow>
<mi>f</mi>
<mo>∈<!-- ∈ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>
</mrow>
</mrow>
</mrow>
</munder>
</mrow>
<mrow>
<mo>(</mo>
<mrow>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>l</mi>
</mfrac>
</mrow>
<mstyle displaystyle="true" scriptlevel="0">
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
</mrow>
</munderover>
<mi>V</mi>
<mo stretchy="false">(</mo>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo>,</mo>
<msub>
<mi>y</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo>+</mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>A</mi>
</mrow>
</msub>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<mi>f</mi>
<msubsup>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msubsup>
<mo>+</mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>I</mi>
</mrow>
</msub>
<msub>
<mo>∫<!-- ∫ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>
</mrow>
</mrow>
</msub>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<msub>
<mi mathvariant="normal">∇<!-- ∇ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>
</mrow>
</mrow>
</msub>
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<msup>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mi>d</mi>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<mo>)</mo>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\underset {f\in {\mathcal {H}}}{\operatorname {argmin} }}\left({\frac {1}{l}}\displaystyle \sum _{i=1}^{l}V(f(x_{i}),y_{i})+\lambda _{A}\|f\|_{\mathcal {H}}^{2}+\lambda _{I}\int _{\mathcal {M}}\|\nabla _{\mathcal {M}}f(x)\|^{2}dp(x)\right)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\underset {f\in {\mathcal {H}}}{\operatorname {argmin} }}\left({\frac {1}{l}}\displaystyle \sum _{i=1}^{l}V(f(x_{i}),y_{i})+\lambda _{A}\|f\|_{\mathcal {H}}^{2}+\lambda _{I}\int _{\mathcal {M}}\|\nabla _{\mathcal {M}}f(x)\|^{2}dp(x)\right)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f33f9ab7b0ce90d7a27a4d16f934bacf1cb515f7" style="vertical-align: -3.171ex; width:66.97ex; height:7.509ex;"/></span><sup class="reference" id="cite_ref-SSL_EoML_9-2"><a href="#cite_note-SSL_EoML-9">[9]</a></sup></dd></dl>
<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\mathcal {H}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>
</mrow>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\mathcal {H}}}</annotation>
</semantics>
</math></span><img alt="{\mathcal {H}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;"/></span> is a reproducing kernel Hilbert space and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\mathcal {M}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>
</mrow>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\mathcal {M}}}</annotation>
</semantics>
</math></span><img alt="{\mathcal {M}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2cc2abebd45ec020509a0ec548b67c9a2cb7cecd" style="vertical-align: -0.338ex; width:2.791ex; height:2.176ex;"/></span> is the manifold on which the data lie.  The regularization parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{A}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>A</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{A}}</annotation>
</semantics>
</math></span><img alt="\lambda _{A}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a3bcf5b35ccd34136b0529d005ffa35e142f2da" style="vertical-align: -0.671ex; width:2.82ex; height:2.509ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{I}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>I</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{I}}</annotation>
</semantics>
</math></span><img alt="\lambda _{I}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dafdfbafa01e15e5f05c424bd33e41802320399f" style="vertical-align: -0.671ex; width:2.416ex; height:2.509ex;"/></span> control smoothness in the ambient and intrinsic spaces respectively.  The graph is used to approximate the intrinsic regularization term.  Defining the <a href="/wiki/Laplacian_matrix" title="Laplacian matrix">graph Laplacian</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle L=D-W}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>L</mi>
<mo>=</mo>
<mi>D</mi>
<mo>−<!-- − --></mo>
<mi>W</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle L=D-W}</annotation>
</semantics>
</math></span><img alt="L=D-W" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14ee07ee510ca6515e6668dca08cf5a0de2c2544" style="vertical-align: -0.505ex; width:11.881ex; height:2.343ex;"/></span> where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle D_{ii}=\sum _{j=1}^{l+u}W_{ij}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>D</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</munderover>
<msub>
<mi>W</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle D_{ii}=\sum _{j=1}^{l+u}W_{ij}}</annotation>
</semantics>
</math></span><img alt="D_{ii}=\sum _{j=1}^{l+u}W_{ij}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aa57df37ac824bc13805e4ec8a46f813954b4414" style="vertical-align: -3.338ex; width:13.803ex; height:7.676ex;"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {f} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">f</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {f} }</annotation>
</semantics>
</math></span><img alt="\mathbf {f} " aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dc6194e680a4e7c521f2178c50eea302843a852d" style="vertical-align: -0.338ex; width:1.053ex; height:2.176ex;"/></span> the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle [f(x_{1})\dots f(x_{l+u})]}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">[</mo>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo>…<!-- … --></mo>
<mi>f</mi>
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle [f(x_{1})\dots f(x_{l+u})]}</annotation>
</semantics>
</math></span><img alt="[f(x_{1})\dots f(x_{l+u})]" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6fc6d44b39ef81da8df4a1be81285c9d6045154b" style="vertical-align: -0.838ex; width:17.622ex; height:2.843ex;"/></span>, we have
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbf {f} ^{T}L\mathbf {f} =\displaystyle \sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\approx \int _{\mathcal {M}}\|\nabla _{\mathcal {M}}f(x)\|^{2}dp(x)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">f</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>T</mi>
</mrow>
</msup>
<mi>L</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="bold">f</mi>
</mrow>
<mo>=</mo>
<mstyle displaystyle="true" scriptlevel="0">
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>,</mo>
<mi>j</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</munderover>
<msub>
<mi>W</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<msub>
<mi>f</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mi>f</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<msup>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo>≈<!-- ≈ --></mo>
<msub>
<mo>∫<!-- ∫ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>
</mrow>
</mrow>
</msub>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<msub>
<mi mathvariant="normal">∇<!-- ∇ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>
</mrow>
</mrow>
</msub>
<mi>f</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<msup>
<mo fence="false" stretchy="false">‖<!-- ‖ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mi>d</mi>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbf {f} ^{T}L\mathbf {f} =\displaystyle \sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\approx \int _{\mathcal {M}}\|\nabla _{\mathcal {M}}f(x)\|^{2}dp(x)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \mathbf {f} ^{T}L\mathbf {f} =\displaystyle \sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\approx \int _{\mathcal {M}}\|\nabla _{\mathcal {M}}f(x)\|^{2}dp(x)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ff2e4d31e189b9d0c55afd5f39fb878d546fe63" style="vertical-align: -3.338ex; width:50.247ex; height:7.676ex;"/></span>.</dd></dl>
<p>The Laplacian can also be used to extend the supervised learning algorithms： regularized least squares and support vector machines (SVM) to semi-supervised versions Laplacian regularized least squares and Laplacian SVM.
</p>
<h3><span class="mw-headline" id="Heuristic_approaches">Heuristic approaches</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=10" title="Edit section: Heuristic approaches">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Some methods for semi-supervised learning are not intrinsically geared to learning from both unlabeled and labeled data, but instead make use of unlabeled data within a supervised learning framework.  For instance, the labeled and unlabeled examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{1},\dots ,x_{l+u}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>l</mi>
<mo>+</mo>
<mi>u</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{1},\dots ,x_{l+u}}</annotation>
</semantics>
</math></span><img alt="x_{1},\dots ,x_{l+u}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/48fa9a910a81b5833b529973e1511c5be43ce25f" style="vertical-align: -0.671ex; width:11.833ex; height:2.009ex;"/></span> may inform a choice of representation, <a class="mw-redirect" href="/wiki/Distance_metric" title="Distance metric">distance metric</a>, or <a class="new" href="/w/index.php?title=Kernel(statistics)&amp;action=edit&amp;redlink=1" title="Kernel(statistics) (page does not exist)">kernel</a> for the data in an unsupervised first step.  Then supervised learning proceeds from only the labeled examples.
</p><p><i>Self-training</i> is a wrapper method for semi-supervised learning.<sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup>  First a supervised learning algorithm is trained based on the labeled data only.  This classifier is then applied to the unlabeled data to generate more labeled examples as input for the supervised learning algorithm.  Generally only the labels the classifier is most confident of are added at each step.<sup class="reference" id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>
</p><p><a href="/wiki/Co-training" title="Co-training">Co-training</a> is an extension of self-training in which multiple classifiers are trained on different (ideally disjoint) sets of features and generate labeled examples for one another.<sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup>
</p>
<h2><span class="mw-headline" id="In_human_cognition">In human cognition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=11" title="Edit section: In human cognition">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Human responses to formal semi-supervised learning problems have yielded varying conclusions about the degree of influence of the unlabeled data (for a summary see<sup class="reference" id="cite_ref-ZhuGoldberg_15-0"><a href="#cite_note-ZhuGoldberg-15">[15]</a></sup>).  More natural learning problems may also be viewed as instances of semi-supervised learning.  Much of human <a href="/wiki/Concept_learning" title="Concept learning">concept learning</a> involves a small amount of direct instruction (e.g. parental labeling of objects during childhood) combined with large amounts of unlabeled experience (e.g. observation of objects without naming or counting them, or at least without feedback).
</p><p>Human infants are sensitive to the structure of unlabeled natural categories such as images of dogs and cats or male and female faces.<sup class="reference" id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup>  More recent work has shown that infants and children take into account not only the unlabeled examples available, but the <a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">sampling</a> process from which labeled examples arise.<sup class="reference" id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup><sup class="reference" id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=12" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a class="mw-redirect" href="/wiki/PU_learning" title="PU learning">PU learning</a></li>
<li><a href="/wiki/Weak_supervision" title="Weak supervision">Weak supervision</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=13" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><cite class="citation journal">"Semi-Supervised Learning Literature Survey, Page 6". 2007. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.99.9681" rel="nofollow">10.1.1.99.9681</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Semi-Supervised+Learning+Literature+Survey%2C+Page+6&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.99.9681&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">|journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><style data-mw-deduplicate="TemplateStyles:r886058088">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-Chapelle-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-Chapelle_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Chapelle_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation book">Chapelle, Olivier; Schölkopf, Bernhard; Zien, Alexander (2006). <i>Semi-supervised learning</i>. Cambridge, Mass.: MIT Press. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-262-03358-9" title="Special:BookSources/978-0-262-03358-9"><bdi>978-0-262-03358-9</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Semi-supervised+learning&amp;rft.place=Cambridge%2C+Mass.&amp;rft.pub=MIT+Press&amp;rft.date=2006&amp;rft.isbn=978-0-262-03358-9&amp;rft.aulast=Chapelle&amp;rft.aufirst=Olivier&amp;rft.au=Sch%C3%B6lkopf%2C+Bernhard&amp;rft.au=Zien%2C+Alexander&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-StevensKN-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-StevensKN_3-0">^</a></b></span> <span class="reference-text">Stevens, K.N.(2000), Acoustic Phonetics, MIT Press, <link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/0-262-69250-3" title="Special:BookSources/0-262-69250-3">0-262-69250-3</a>, 978-0-262-69250-2</span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">Scudder, H.J. <a class="external text" href="https://ieeexplore.ieee.org/abstract/document/1053799/" rel="nofollow">Probability of Error of Some Adaptive Pattern-Recognition Machines</a>. IEEE Transactions on Information Theory, 11:363–371 (1965). Cited in Chapelle et al. 2006, page 3.</span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">Vapnik, V. and Chervonenkis, A. Theory of Pattern Recognition [in Russian].  Nauka, Moscow (1974). Cited in Chapelle et al. 2006, page 3.</span>
</li>
<li id="cite_note-Ratsaby-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-Ratsaby_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Ratsaby_6-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Ratsaby, J. and Venkatesh, S. <a class="external text" href="http://www.ariel.ac.il/sites/ratsaby/Publications/PDF/colt95.pdf" rel="nofollow">Learning from a mixture of labeled and unlabeled examples with parametric side information</a>. In <i>Proceedings of the Eighth Annual Conference on Computational Learning Theory</i>, pages 412-417 (1995). Cited in Chapelle et al. 2006, page 4.</span>
</li>
<li id="cite_note-survey-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-survey_7-0">^</a></b></span> <span class="reference-text">Zhu, Xiaojin. <a class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf" rel="nofollow">Semi-supervised learning literature survey</a>. Computer Sciences, University of Wisconsin-Madison (2008).</span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text">Cozman, F. and Cohen, I. Risks of semi-supervised learning: how unlabeled data can degrade performance of generative classifiers.  In: Chapelle et al. (2006).</span>
</li>
<li id="cite_note-SSL_EoML-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-SSL_EoML_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-SSL_EoML_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-SSL_EoML_9-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">Zhu, Xiaojin. <a class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/pub/SSL_EoML.pdf" rel="nofollow">Semi-Supervised Learning</a> University of Wisconsin-Madison.</span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation journal">M. Belkin; P. Niyogi (2004). <a class="external text" href="http://booksc.org/dl/11288633/421f61" rel="nofollow">"Semi-supervised Learning on Riemannian Manifolds"</a>. <i>Machine Learning</i>. <b>56</b> (Special Issue on Clustering): 209–239. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="//doi.org/10.1023%2Fb%3Amach.0000033120.25363.1e" rel="nofollow">10.1023/b:mach.0000033120.25363.1e</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Semi-supervised+Learning+on+Riemannian+Manifolds&amp;rft.volume=56&amp;rft.issue=Special+Issue+on+Clustering&amp;rft.pages=209-239&amp;rft.date=2004&amp;rft_id=info%3Adoi%2F10.1023%2Fb%3Amach.0000033120.25363.1e&amp;rft.au=M.+Belkin&amp;rft.au=P.+Niyogi&amp;rft_id=http%3A%2F%2Fbooksc.org%2Fdl%2F11288633%2F421f61&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">M. Belkin, P. Niyogi, V. Sindhwani. On Manifold Regularization. AISTATS 2005.</span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite class="citation journal">Triguero, Isaac; García, Salvador; Herrera, Francisco (2013-11-26). "Self-labeled techniques for semi-supervised learning: taxonomy, software and empirical study". <i>Knowledge and Information Systems</i>. <b>42</b> (2): 245–284. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="//doi.org/10.1007%2Fs10115-013-0706-y" rel="nofollow">10.1007/s10115-013-0706-y</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a> <a class="external text" href="//www.worldcat.org/issn/0219-1377" rel="nofollow">0219-1377</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Knowledge+and+Information+Systems&amp;rft.atitle=Self-labeled+techniques+for+semi-supervised+learning%3A+taxonomy%2C+software+and+empirical+study&amp;rft.volume=42&amp;rft.issue=2&amp;rft.pages=245-284&amp;rft.date=2013-11-26&amp;rft_id=info%3Adoi%2F10.1007%2Fs10115-013-0706-y&amp;rft.issn=0219-1377&amp;rft.aulast=Triguero&amp;rft.aufirst=Isaac&amp;rft.au=Garc%C3%ADa%2C+Salvador&amp;rft.au=Herrera%2C+Francisco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation journal">Fazakis, Nikos; Karlos, Stamatis; Kotsiantis, Sotiris; Sgarbas, Kyriakos (2015-12-29). <a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4709606" rel="nofollow">"Self-Trained LMT for Semisupervised Learning"</a>. <i>Computational Intelligence and Neuroscience</i>. <b>2016</b>: 3057481. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="//doi.org/10.1155%2F2016%2F3057481" rel="nofollow">10.1155/2016/3057481</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4709606" rel="nofollow">4709606</a></span>. <a class="mw-redirect" href="/wiki/PubMed_Identifier" title="PubMed Identifier">PMID</a> <a class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/26839531" rel="nofollow">26839531</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computational+Intelligence+and+Neuroscience&amp;rft.atitle=Self-Trained+LMT+for+Semisupervised+Learning&amp;rft.volume=2016&amp;rft.pages=3057481&amp;rft.date=2015-12-29&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4709606&amp;rft_id=info%3Apmid%2F26839531&amp;rft_id=info%3Adoi%2F10.1155%2F2016%2F3057481&amp;rft.aulast=Fazakis&amp;rft.aufirst=Nikos&amp;rft.au=Karlos%2C+Stamatis&amp;rft.au=Kotsiantis%2C+Sotiris&amp;rft.au=Sgarbas%2C+Kyriakos&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4709606&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation book">Didaci, Luca; Fumera, Giorgio; Roli, Fabio (2012-11-07).  Gimel’farb, Georgy; Hancock, Edwin; Imiya, Atsushi; Kuijper, Arjan; Kudo, Mineichi; Omachi, Shinichiro; Windeatt, Terry; Yamada, Keiji (eds.). <i>Analysis of Co-training Algorithm with Very Small Training Sets</i>. Lecture Notes in Computer Science. Springer Berlin Heidelberg. pp. 719–726. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="//doi.org/10.1007%2F978-3-642-34166-3_79" rel="nofollow">10.1007/978-3-642-34166-3_79</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/9783642341656" title="Special:BookSources/9783642341656"><bdi>9783642341656</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Analysis+of+Co-training+Algorithm+with+Very+Small+Training+Sets&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=719-726&amp;rft.pub=Springer+Berlin+Heidelberg&amp;rft.date=2012-11-07&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-642-34166-3_79&amp;rft.isbn=9783642341656&amp;rft.aulast=Didaci&amp;rft.aufirst=Luca&amp;rft.au=Fumera%2C+Giorgio&amp;rft.au=Roli%2C+Fabio&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-ZhuGoldberg-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-ZhuGoldberg_15-0">^</a></b></span> <span class="reference-text">
<cite class="citation book">Zhu, Xiaojin; Goldberg, Andrew B. (2009). <i>Introduction to semi-supervised learning</i>. Morgan &amp; Claypool. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/9781598295481" title="Special:BookSources/9781598295481"><bdi>9781598295481</bdi></a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+semi-supervised+learning.&amp;rft.pub=Morgan+%26+Claypool&amp;rft.date=2009&amp;rft.isbn=9781598295481&amp;rft.aulast=Zhu&amp;rft.aufirst=Xiaojin&amp;rft.au=Goldberg%2C+Andrew+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation journal">Younger B. A.; Fearing D. D. (1999). "Parsing Items into Separate Categories: Developmental Change in Infant Categorization". <i>Child Development</i>. <b>70</b> (2): 291–303. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="//doi.org/10.1111%2F1467-8624.00022" rel="nofollow">10.1111/1467-8624.00022</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Child+Development&amp;rft.atitle=Parsing+Items+into+Separate+Categories%3A+Developmental+Change+in+Infant+Categorization&amp;rft.volume=70&amp;rft.issue=2&amp;rft.pages=291-303&amp;rft.date=1999&amp;rft_id=info%3Adoi%2F10.1111%2F1467-8624.00022&amp;rft.au=Younger+B.+A.&amp;rft.au=Fearing+D.+D.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation journal">Xu, F. &amp; Tenenbaum, J. B. (2007). "Sensitivity to sampling in Bayesian word learning. Developmental Science". <i>Developmental Science</i>. <b>10</b> (3): 288–297. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.7505" rel="nofollow">10.1.1.141.7505</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="//doi.org/10.1111%2Fj.1467-7687.2007.00590.x" rel="nofollow">10.1111/j.1467-7687.2007.00590.x</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Developmental+Science&amp;rft.atitle=Sensitivity+to+sampling+in+Bayesian+word+learning.+Developmental+Science&amp;rft.volume=10&amp;rft.issue=3&amp;rft.pages=288-297&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.141.7505&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1467-7687.2007.00590.x&amp;rft.au=Xu%2C+F.&amp;rft.au=Tenenbaum%2C+J.+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gweon, H., Tenenbaum J.B., and Schulz L.E (2010). <a class="external text" href="http://www.pnas.org/content/107/20/9066" rel="nofollow">"Infants consider both the sample and the sampling process in inductive generalization"</a>. <i>Proc Natl Acad Sci U S A</i>. <b>107</b> (20): 9066–71. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a class="external text" href="//doi.org/10.1073%2Fpnas.1003095107" rel="nofollow">10.1073/pnas.1003095107</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a> <span class="cs1-lock-free" title="Freely accessible"><a class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2889113" rel="nofollow">2889113</a></span>. <a class="mw-redirect" href="/wiki/PubMed_Identifier" title="PubMed Identifier">PMID</a> <a class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/20435914" rel="nofollow">20435914</a>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc+Natl+Acad+Sci+U+S+A&amp;rft.atitle=Infants+consider+both+the+sample+and+the+sampling+process+in+inductive+generalization&amp;rft.volume=107&amp;rft.issue=20&amp;rft.pages=9066-71&amp;rft.date=2010&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2889113&amp;rft_id=info%3Apmid%2F20435914&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.1003095107&amp;rft.au=Gweon%2C+H.%2C+Tenenbaum+J.B.%2C+and+Schulz+L.E&amp;rft_id=http%3A%2F%2Fwww.pnas.org%2Fcontent%2F107%2F20%2F9066&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning"></span><span class="cs1-maint citation-comment">CS1 maint: multiple names: authors list (<a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>)</span><link href="mw-data:TemplateStyles:r886058088" rel="mw-deduplicated-inline-style"/></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=14" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a class="external autonumber" href="http://manifold.cs.uchicago.edu/manifold_regularization/software.html" rel="nofollow">[1]</a> A freely available <a href="/wiki/MATLAB" title="MATLAB">MATLAB</a> implementation of the graph-based semi-supervised algorithms Laplacian support vector machines and Laplacian regularized least squares.</li>
<li><a class="external autonumber" href="http://sci2s.ugr.es/keel/algorithms.php#sub10" rel="nofollow">[2]</a> KEEL module for semi-supervised learning.</li>
<li><a class="external autonumber" href="http://pages.cs.wisc.edu/~jerryzhu/ssl/software.html" rel="nofollow">[3]</a> Semi-Supervised Learning Software</li>
<li><a class="external autonumber" href="http://scikit-learn.org/stable/modules/label_propagation.html" rel="nofollow">[4]</a> Semi-Supervised algorithms in scikit-learn  .</li></ul>
<!-- 
NewPP limit report
Parsed by mw1319
Cached time: 20190918205612
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.464 seconds
Real time usage: 0.656 seconds
Preprocessor visited node count: 1424/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 49746/2097152 bytes
Template argument size: 1759/2097152 bytes
Highest expansion depth: 15/40
Expensive parser function count: 5/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 40352/5000000 bytes
Number of Wikibase entities loaded: 4/400
Lua time usage: 0.201/10.000 seconds
Lua memory usage: 4.31 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  451.531      1 -total
 69.44%  313.527      1 Template:Reflist
 47.32%  213.685      7 Template:Cite_journal
 13.88%   62.674      1 Template:Machine_learning_bar
 12.65%   57.114      1 Template:Sidebar_with_collapsible_lists
 12.08%   54.536      1 Template:Disputed_inline
 10.77%   48.637      1 Template:Fix
  9.64%   43.533      1 Template:ISBN
  6.99%   31.552      1 Template:Category_handler
  6.18%   27.926      3 Template:Cite_book
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:2829632-0!canonical!math=5 and timestamp 20190918205611 and revision id 913183638
 -->
</div><noscript><img alt="" height="1" src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" style="border: none; position: absolute;" title="" width="1"/></noscript></div>
<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;oldid=913183638">https://en.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;oldid=913183638</a>"</div>
<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li></ul></div><div class="mw-hidden-catlinks mw-hidden-cats-hidden" id="mw-hidden-catlinks">Hidden categories: <ul><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">CS1 maint: multiple names: authors list</a></li><li><a href="/wiki/Category:All_accuracy_disputes" title="Category:All accuracy disputes">All accuracy disputes</a></li><li><a href="/wiki/Category:Articles_with_disputed_statements_from_November_2017" title="Category:Articles with disputed statements from November 2017">Articles with disputed statements from November 2017</a></li></ul></div></div>
<div class="visualClear"></div>
</div>
</div>
<div id="mw-data-after-content">
<div class="read-more-container"></div>
</div>
<div id="mw-navigation">
<h2>Navigation menu</h2>
<div id="mw-head">
<div aria-labelledby="p-personal-label" id="p-personal" role="navigation">
<h3 id="p-personal-label">Personal tools</h3>
<ul>
<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a accesskey="n" href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]">Talk</a></li><li id="pt-anoncontribs"><a accesskey="y" href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Semi-supervised+learning" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a accesskey="o" href="/w/index.php?title=Special:UserLogin&amp;returnto=Semi-supervised+learning" title="You're encouraged to log in; however, it's not mandatory. [o]">Log in</a></li> </ul>
</div>
<div id="left-navigation">
<div aria-labelledby="p-namespaces-label" class="vectorTabs" id="p-namespaces" role="navigation">
<h3 id="p-namespaces-label">Namespaces</h3>
<ul>
<li class="selected" id="ca-nstab-main"><span><a accesskey="c" href="/wiki/Semi-supervised_learning" title="View the content page [c]">Article</a></span></li><li id="ca-talk"><span><a accesskey="t" href="/wiki/Talk:Semi-supervised_learning" rel="discussion" title="Discussion about the content page [t]">Talk</a></span></li> </ul>
</div>
<div aria-labelledby="p-variants-label" class="vectorMenu emptyPortlet" id="p-variants" role="navigation">
<input aria-labelledby="p-variants-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-variants-label">
<span>Variants</span>
</h3>
<ul class="menu">
</ul>
</div>
</div>
<div id="right-navigation">
<div aria-labelledby="p-views-label" class="vectorTabs" id="p-views" role="navigation">
<h3 id="p-views-label">Views</h3>
<ul>
<li class="collapsible selected" id="ca-view"><span><a href="/wiki/Semi-supervised_learning">Read</a></span></li><li class="collapsible" id="ca-edit"><span><a accesskey="e" href="/w/index.php?title=Semi-supervised_learning&amp;action=edit" title="Edit this page [e]">Edit</a></span></li><li class="collapsible" id="ca-history"><span><a accesskey="h" href="/w/index.php?title=Semi-supervised_learning&amp;action=history" title="Past revisions of this page [h]">View history</a></span></li> </ul>
</div>
<div aria-labelledby="p-cactions-label" class="vectorMenu emptyPortlet" id="p-cactions" role="navigation">
<input aria-labelledby="p-cactions-label" class="vectorMenuCheckbox" type="checkbox"/>
<h3 id="p-cactions-label"><span>More</span></h3>
<ul class="menu">
</ul>
</div>
<div id="p-search" role="search">
<h3>
<label for="searchInput">Search</label>
</h3>
<form action="/w/index.php" id="searchform">
<div id="simpleSearch">
<input accesskey="f" id="searchInput" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" type="search"/><input name="title" type="hidden" value="Special:Search"/><input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="Search Wikipedia for this text" type="submit" value="Search"/><input class="searchButton" id="searchButton" name="go" title="Go to a page with this exact name if it exists" type="submit" value="Go"/> </div>
</form>
</div>
</div>
</div>
<div id="mw-panel">
<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a></div>
<div aria-labelledby="p-navigation-label" class="portal" id="p-navigation" role="navigation">
<h3 id="p-navigation-label">Navigation</h3>
<div class="body">
<ul>
<li id="n-mainpage-description"><a accesskey="z" href="/wiki/Main_Page" title="Visit the main page [z]">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a accesskey="x" href="/wiki/Special:Random" title="Load a random article [x]">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li> </ul>
</div>
</div>
<div aria-labelledby="p-interaction-label" class="portal" id="p-interaction" role="navigation">
<h3 id="p-interaction-label">Interaction</h3>
<div class="body">
<ul>
<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a accesskey="r" href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li> </ul>
</div>
</div>
<div aria-labelledby="p-tb-label" class="portal" id="p-tb" role="navigation">
<h3 id="p-tb-label">Tools</h3>
<div class="body">
<ul>
<li id="t-whatlinkshere"><a accesskey="j" href="/wiki/Special:WhatLinksHere/Semi-supervised_learning" title="List of all English Wikipedia pages containing links to this page [j]">What links here</a></li><li id="t-recentchangeslinked"><a accesskey="k" href="/wiki/Special:RecentChangesLinked/Semi-supervised_learning" rel="nofollow" title="Recent changes in pages linked from this page [k]">Related changes</a></li><li id="t-upload"><a accesskey="u" href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]">Upload file</a></li><li id="t-specialpages"><a accesskey="q" href="/wiki/Special:SpecialPages" title="A list of all special pages [q]">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Semi-supervised_learning&amp;oldid=913183638" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Semi-supervised_learning&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a accesskey="g" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1041418" title="Link to connected data repository item [g]">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Semi-supervised_learning&amp;id=913183638" title="Information on how to cite this page">Cite this page</a></li> </ul>
</div>
</div>
<div aria-labelledby="p-coll-print_export-label" class="portal" id="p-coll-print_export" role="navigation">
<h3 id="p-coll-print_export-label">Print/export</h3>
<div class="body">
<ul>
<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Semi-supervised+learning">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Semi-supervised+learning&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a accesskey="p" href="/w/index.php?title=Semi-supervised_learning&amp;printable=yes" title="Printable version of this page [p]">Printable version</a></li> </ul>
</div>
</div>
<div aria-labelledby="p-lang-label" class="portal" id="p-lang" role="navigation">
<h3 id="p-lang-label">Languages</h3>
<div class="body">
<ul>
<li class="interlanguage-link interwiki-es"><a class="interlanguage-link-target" href="https://es.wikipedia.org/wiki/Aprendizaje_semisupervisado" hreflang="es" lang="es" title="Aprendizaje semisupervisado – Spanish">Español</a></li><li class="interlanguage-link interwiki-fa"><a class="interlanguage-link-target" href="https://fa.wikipedia.org/wiki/%DB%8C%D8%A7%D8%AF%DA%AF%DB%8C%D8%B1%DB%8C_%D9%86%DB%8C%D9%85%D9%87%E2%80%8C%D9%86%D8%B8%D8%A7%D8%B1%D8%AA%DB%8C" hreflang="fa" lang="fa" title="یادگیری نیمه‌نظارتی – Persian">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a class="interlanguage-link-target" href="https://fr.wikipedia.org/wiki/Apprentissage_semi-supervis%C3%A9" hreflang="fr" lang="fr" title="Apprentissage semi-supervisé – French">Français</a></li><li class="interlanguage-link interwiki-ko"><a class="interlanguage-link-target" href="https://ko.wikipedia.org/wiki/%EC%A4%80_%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5" hreflang="ko" lang="ko" title="준 지도 학습 – Korean">한국어</a></li><li class="interlanguage-link interwiki-ru"><a class="interlanguage-link-target" href="https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%87%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%BD%D1%8B%D0%BC_%D0%BF%D1%80%D0%B8%D0%B2%D0%BB%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F" hreflang="ru" lang="ru" title="Обучение с частичным привлечением учителя – Russian">Русский</a></li><li class="interlanguage-link interwiki-uk"><a class="interlanguage-link-target" href="https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D0%BF%D1%96%D0%B2%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%BD%D0%B5_%D0%BD%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F" hreflang="uk" lang="uk" title="Напівавтоматичне навчання – Ukrainian">Українська</a></li><li class="interlanguage-link interwiki-vi"><a class="interlanguage-link-target" href="https://vi.wikipedia.org/wiki/H%E1%BB%8Dc_n%E1%BB%ADa_gi%C3%A1m_s%C3%A1t" hreflang="vi" lang="vi" title="Học nửa giám sát – Vietnamese">Tiếng Việt</a></li> </ul>
<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a class="wbc-editpage" href="https://www.wikidata.org/wiki/Special:EntityPage/Q1041418#sitelinks-wikipedia" title="Edit interlanguage links">Edit links</a></span></div> </div>
</div>
</div>
</div>
<div id="footer" role="contentinfo">
<ul id="footer-info">
<li id="footer-info-lastmod"> This page was last edited on 30 August 2019, at 13:04<span class="anonymous-show"> (UTC)</span>.</li>
<li id="footer-info-copyright">Text is available under the <a href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="license">Creative Commons Attribution-ShareAlike License</a><a href="//creativecommons.org/licenses/by-sa/3.0/" rel="license" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>
<ul id="footer-places">
<li id="footer-places-privacy"><a class="extiw" href="https://foundation.wikimedia.org/wiki/Privacy_policy" title="wmf:Privacy policy">Privacy policy</a></li>
<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
<li id="footer-places-mobileview"><a class="noprint stopMobileRedirectToggle" href="//en.m.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;mobileaction=toggle_view_mobile">Mobile view</a></li>
</ul>
<ul class="noprint" id="footer-icons">
<li id="footer-copyrightico">
<a href="https://wikimediafoundation.org/"><img alt="Wikimedia Foundation" height="31" src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88"/></a> </li>
<li id="footer-poweredbyico">
<a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" src="/static/images/poweredby_mediawiki_88x31.png" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88"/></a> </li>
</ul>
<div style="clear: both;"></div>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.464","walltime":"0.656","ppvisitednodes":{"value":1424,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":49746,"limit":2097152},"templateargumentsize":{"value":1759,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":5,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":40352,"limit":5000000},"entityaccesscount":{"value":4,"limit":400},"timingprofile":["100.00%  451.531      1 -total"," 69.44%  313.527      1 Template:Reflist"," 47.32%  213.685      7 Template:Cite_journal"," 13.88%   62.674      1 Template:Machine_learning_bar"," 12.65%   57.114      1 Template:Sidebar_with_collapsible_lists"," 12.08%   54.536      1 Template:Disputed_inline"," 10.77%   48.637      1 Template:Fix","  9.64%   43.533      1 Template:ISBN","  6.99%   31.552      1 Template:Category_handler","  6.18%   27.926      3 Template:Cite_book"]},"scribunto":{"limitreport-timeusage":{"value":"0.201","limit":"10.000"},"limitreport-memusage":{"value":4524165,"limit":52428800}},"cachereport":{"origin":"mw1319","timestamp":"20190918205612","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Semi-supervised learning","url":"https:\/\/en.wikipedia.org\/wiki\/Semi-supervised_learning","sameAs":"http:\/\/www.wikidata.org\/entity\/Q1041418","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q1041418","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2005-10-04T04:19:02Z","dateModified":"2019-08-30T13:04:25Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/d\/d0\/Example_of_unlabeled_data_in_semisupervised_learning.png","headline":"class of machine learning techniques"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":129,"wgHostname":"mw1251"});});</script>
</body>
</html>
